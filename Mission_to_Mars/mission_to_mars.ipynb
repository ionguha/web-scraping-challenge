{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mission to Mars](https://www.intrepidmuseum.org/The-Intrepid-Experience/Past-Exhibitions/Mission-to-Mars-(Mars-Rover-exhibit)/images/mars_banner.aspx?width=676&height=268)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "# Beautiful Soup is a Python library for pulling data out of HTML files\n",
    "from bs4 import BeautifulSoup \n",
    "# Requests library is the de facto standard for making HTTP requests in Python\n",
    "import requests\n",
    "# Splinter is an open source tool for testing web applications using Python\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False) # otherwise defaults to FireFox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url_to_scrape = \"https://mars.nasa.gov/news/\"\n",
    "# Visit the url using browser.visit method\n",
    "browser.visit(url_to_scrape)\n",
    "# Time delay of 2 sec to make sure the browser loads\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWebpage Title: \n",
      " News  – NASA’s Mars Exploration Program \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the title of the web page\n",
    "print('\\033[1m'+\"Webpage Title: \\n {}\".format(soup.title.string) + '\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the first five news titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the website we see that news title are wrapped as <div class=\"content_title\">\n",
    "results = soup.find_all('div', class_=\"content_title\", limit = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'text'\n",
      "--------------------------------------------------------\n",
      "NASA's MAVEN Observes Martian Night Sky Pulsing in Ultraviolet Light\n",
      "--------------------------------------------------------\n",
      "8 Martian Postcards to Celebrate Curiosity's Landing Anniversary\n",
      "--------------------------------------------------------\n",
      "NASA, ULA Launch Mars 2020 Perseverance Rover Mission to Red Planet\n",
      "--------------------------------------------------------\n",
      "NASA's Perseverance Rover Will Carry First Spacesuit Materials to Mars\n"
     ]
    }
   ],
   "source": [
    "# Let's define lists to hold titles & links\n",
    "titles = []\n",
    "# Loop through returned results\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return title of listing\n",
    "        title = result.find('a').text\n",
    "        # Print results only if title is available\n",
    "        if (title):\n",
    "            print(\"--------------------------------------------------------\")\n",
    "            print(title)\n",
    "            titles.append(title) # Append the titles list            \n",
    "    except AttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe first title: \n",
      " NASA's MAVEN Observes Martian Night Sky Pulsing in Ultraviolet Light\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m'+\"The first title: \\n {}\".format(titles[0]) + '\\033[0m') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the first five paragraph texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the website we see that paragraph text are wrapped as <div class=\"article_teaser_body\">\n",
    "results = soup.find_all('div', class_=\"article_teaser_body\", limit = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Vast areas of the Martian night sky pulse in ultraviolet light, according to images from NASA’s MAVEN spacecraft. The results are being used to illuminate complex circulation patterns in the Martian atmosphere.\n",
      "--------------------------------------------------------\n",
      "The NASA rover touched down eight years ago, on Aug. 5, 2012, and will soon be joined by a second rover, Perseverance.\n",
      "--------------------------------------------------------\n",
      "The agency's Mars 2020 mission is on its way. It will land at Jezero Crater in about seven months, on Feb. 18, 2021. \n",
      "--------------------------------------------------------\n",
      "In a Q&A, spacesuit designer Amy Ross explains how five samples, including a piece of helmet visor, will be tested aboard the rover, which is targeting a July 30 launch. \n",
      "--------------------------------------------------------\n",
      "With a targeted launch date of July 30, the next robotic scientist NASA is sending to the to the Red Planet has big ambitions.\n"
     ]
    }
   ],
   "source": [
    "# Let's define lists to hold paragraph texts\n",
    "texts = []\n",
    "# Loop through returned results\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return the paragraph\n",
    "        news_p = result.text # Append the paragraph list\n",
    "        # Print results only if paragraph is available\n",
    "        if news_p :\n",
    "            print(\"--------------------------------------------------------\")\n",
    "            print(news_p)\n",
    "            texts.append(news_p)\n",
    "    except AttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe first paragraph: \n",
      " Vast areas of the Martian night sky pulse in ultraviolet light, according to images from NASA’s MAVEN spacecraft. The results are being used to illuminate complex circulation patterns in the Martian atmosphere.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m'+\"The first paragraph: \\n {}\".format(texts[0]) + '\\033[0m') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing browser using browser.quit:\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url_to_scrape = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "# Visit the url using browser.visit method\n",
    "response = browser.visit(url_to_scrape)\n",
    "# Time delay of 2 sec to make sure the browser loads\n",
    "time.sleep(2)\n",
    "button = browser.find_by_id(\"full_image\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWebpage Title: \n",
      " Space Images\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the title of the web page\n",
    "print('\\033[1m'+\"Webpage Title: \\n {}\".format(soup.title.string) + '\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featured image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url(/spaceimages/images/wallpaper/PIA14106-1920x1200.jpg)\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the following line if cssutils is not installed\n",
    "#!pip install cssutils\n",
    "import cssutils\n",
    "# Inspecting the website we see that background image is wrapped as <article class=\"carousel_item\">\n",
    "article_style = soup.find('article')['style']\n",
    "url = cssutils.parseStyle(article_style)['background-image']\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFeatured image url: \n",
      " https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA14106-1920x1200.jpg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Remove extra stuff from the url\n",
    "url = url.replace('url(','').replace(')','')\n",
    "# Combine with base_url to create image url\n",
    "base_url = 'https://www.jpl.nasa.gov'\n",
    "# Create the url for the background image\n",
    "image_url = base_url + url\n",
    "print('\\033[1m'+\"Featured image url: \\n {}\".format(image_url) + '\\033[0m') # Display the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA14106-1920x1200.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"Screenshots/Featured_image.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "from IPython.display import Image\n",
    "print(image_url)\n",
    "# Using the requests library to download and save the image from the featured image url\n",
    "response = requests.get(image_url, stream=True)\n",
    "with open('Screenshots/Featured_image.png', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "# Display the image with IPython.display\n",
    "Image(url='Screenshots/Featured_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing browser using browser.quit:\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url_to_scrape = \"https://twitter.com/marswxreport?lang=en\"\n",
    "# Visit the url using browser.visit method\n",
    "browser.visit(url_to_scrape)\n",
    "# Time delay of 2 sec to make sure the browser loads\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWebpage Title: \n",
      " Mars Weather (@MarsWxReport) / Twitter\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the title of the web page\n",
    "print('\\033[1m'+\"Webpage Title: \\n {}\".format(soup.title.string) + '\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the first five tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find_all('div',attrs={\"data-testid\":\"tweet\"}, limit = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Mars Weather@MarsWxReport·12hInSight sol 602 (2020-08-05) low -91.5ºC (-132.6ºF) high -9.5ºC (14.9ºF)\n",
      "winds from the W at 5.4 m/s (12.2 mph) gusting to 17.0 m/s (38.1 mph)\n",
      "pressure at 7.90 hPa221\n",
      "--------------------------------------------------------\n",
      "Mars Weather@MarsWxReport·Aug 5InSight sol 601 (2020-08-05) low -91.6ºC (-132.9ºF) high -10.6ºC (12.9ºF)\n",
      "winds from the W at 6.0 m/s (13.4 mph) gusting to 16.0 m/s (35.7 mph)\n",
      "pressure at 7.80 hPa1416\n",
      "--------------------------------------------------------\n",
      "Mars Weather@MarsWxReport·Aug 5InSight sol 600 (2020-08-03) low -107.6ºC (-161.7ºF) high -5.7ºC (21.7ºF)\n",
      "winds from the W at 5.6 m/s (12.5 mph) gusting to 15.2 m/s (34.0 mph)\n",
      "pressure at 7.90 hPa618\n",
      "--------------------------------------------------------\n",
      "Mars Weather@MarsWxReport·Aug 4InSight sol 599 (2020-08-02) low -91.8ºC (-133.2ºF) high -42.6ºC (-44.8ºF)\n",
      "winds from the WNW at 5.1 m/s (11.5 mph) gusting to 15.6 m/s (34.8 mph)\n",
      "pressure at 7.90 hPa1223\n",
      "--------------------------------------------------------\n",
      "Mars Weather@MarsWxReport·Aug 2InSight sol 598 (2020-08-01) low -91.6ºC (-132.9ºF) high -15.1ºC (4.8ºF)\n",
      "winds from the WNW at 7.1 m/s (15.8 mph) gusting to 19.2 m/s (43.0 mph)\n",
      "pressure at 7.90 hPa1326\n"
     ]
    }
   ],
   "source": [
    "# Let's define a list to hold the tweets\n",
    "tweets = []\n",
    "# Loop through returned results\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return the tweet\n",
    "        tweet = result.text\n",
    "        tweets.append(tweet) # Append to the list\n",
    "        # Print results only if tweet is available\n",
    "        if tweet :\n",
    "            print(\"--------------------------------------------------------\")\n",
    "            print(tweet)\n",
    "    except AttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sure that the first tweet contains weather information\n",
    "for tweet in tweets:\n",
    "    if 'sol' and 'low' in tweet:\n",
    "        first_tweet = tweet\n",
    "        break\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the headers from the first tweet\n",
    "first_tweet = 'I'+ first_tweet.split('I')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe first tweet: \n",
      " InSight sol 602 (2020-08-05) low -91.5ºC (-132.6ºF) high -9.5ºC (14.9ºF)\n",
      "winds from the W at 5.4 m/s (12.2 mph) gusting to 17.0 m/s (38.1 mph)\n",
      "pressure at 7.90 hPa221\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m'+\"The first tweet: \\n {}\".format(first_tweet) + '\\033[0m') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing browser using browser.quit:\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url_to_scrape = \"https://space-facts.com/mars/\"\n",
    "# Visit the url using browser.visit method\n",
    "browser.visit(url_to_scrape)\n",
    "# Time delay of 2 sec to make sure the browser loads\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWebpage Title: \n",
      " Mars Facts - Interesting Facts about Planet Mars\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the title of the web page\n",
    "print('\\033[1m'+\"Webpage Title: \\n {}\".format(soup.title.string) + '\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the website we see that table is wrapped as <table class=\"content_title\">\n",
    "mars_table = soup.find('table', attrs={\"id\": \"tablepress-p-mars\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTotal number of rows in the table: 9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Let's check the rows in mars_table\n",
    "table_rows = mars_table.find_all('tr')\n",
    "print('\\033[1m'+\"Total number of rows in the table: {}\".format(len(table_rows))+'\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mars Facts</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equatorial Diameter:</td>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polar Diameter:</td>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orbit Distance:</td>\n",
       "      <td>227,943,824 km (1.38 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orbit Period:</td>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Surface Temperature:</td>\n",
       "      <td>-87 to -5 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>First Record:</td>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recorded By:</td>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mars Facts                          Value\n",
       "0  Equatorial Diameter:                       6,792 km\n",
       "1       Polar Diameter:                       6,752 km\n",
       "2                 Mass:  6.39 × 10^23 kg (0.11 Earths)\n",
       "3                Moons:            2 (Phobos & Deimos)\n",
       "4       Orbit Distance:       227,943,824 km (1.38 AU)\n",
       "5         Orbit Period:           687 days (1.9 years)\n",
       "6  Surface Temperature:                   -87 to -5 °C\n",
       "7         First Record:              2nd millennium BC\n",
       "8          Recorded By:           Egyptian astronomers"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "# Let's check the elements in mars_table\n",
    "table_elements = mars_table.find_all('td')\n",
    "# Initiate an array row_values\n",
    "row_values = []\n",
    "# Fill the array row_values\n",
    "for rows in table_rows:\n",
    "     data = rows.find_all('td') # finding the elements in each row\n",
    "     values = [rows.text.strip() for rows in data if rows.text.strip()]\n",
    "     if values:\n",
    "        row_values.append(values) # Adding elements\n",
    "# Initiate column names for the dataframe\n",
    "column_names = [\"Mars Facts\", \"Value\"]\n",
    "# Create the initial pandas dataframe \n",
    "mars_df = pd.DataFrame(row_values, columns=column_names)\n",
    "mars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create html table\n",
    "html_table = mars_df.to_html(classes='table table-striped',index=False)\n",
    "# Uncomment the following line to see the html_table\n",
    "#print(html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing browser using browser.quit:\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base url for the webpage\n",
    "base_url = \"https://astrogeology.usgs.gov\"\n",
    "# URL of page to be scraped\n",
    "url_to_scrape = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "# Visit the url using browser.visit method\n",
    "browser.visit(url_to_scrape)\n",
    "# Time delay of 2 sec to make sure the browser loads\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWebpage Title: \n",
      " Astropedia Search Results | USGS Astrogeology Science Center\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the title of the web page\n",
    "print('\\033[1m'+\"Webpage Title: \\n {}\".format(soup.title.string) + '\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTotal number of links in the webpage: 24\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Let's check the number of links in the webpage\n",
    "Number_of_links = soup.find_all('a')\n",
    "print('\\033[1m'+\"Total number of links in the webpage: {}\".format(len(Number_of_links)) + '\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the website we see that images are wrapped in <div class=\"item\">\n",
    "results = soup.find_all('div', class_=\"item\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title and links to the Mars Hemisphere images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Cerberus Hemisphere Enhanced\n",
      "--------------------------------------------------------\n",
      "https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced\n",
      "--------------------------------------------------------\n",
      "Schiaparelli Hemisphere Enhanced\n",
      "--------------------------------------------------------\n",
      "https://astrogeology.usgs.gov/search/map/Mars/Viking/schiaparelli_enhanced\n",
      "--------------------------------------------------------\n",
      "Syrtis Major Hemisphere Enhanced\n",
      "--------------------------------------------------------\n",
      "https://astrogeology.usgs.gov/search/map/Mars/Viking/syrtis_major_enhanced\n",
      "--------------------------------------------------------\n",
      "Valles Marineris Hemisphere Enhanced\n",
      "--------------------------------------------------------\n",
      "https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced\n"
     ]
    }
   ],
   "source": [
    "# Define lists to store the title and urls\n",
    "titles = []\n",
    "link_urls = []\n",
    "# Loop through returned results\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return text of image headline\n",
    "        title = result.find('h3').text\n",
    "        # Identify and return link of image\n",
    "        link = result.find('a', class_='itemLink product-item')['href']\n",
    "        # Create image url by appending to the base url\n",
    "        image_url = base_url + link\n",
    "        # Print results only if title and link are available\n",
    "        if (title and link):\n",
    "            print(\"--------------------------------------------------------\")\n",
    "            print(title)\n",
    "            titles.append(title)\n",
    "            print(\"--------------------------------------------------------\")\n",
    "            print(image_url)\n",
    "            link_urls.append(image_url)\n",
    "            \n",
    "    except AttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemisphere Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://astrogeology.usgs.gov/cache/images/f5e372a36edfa389625da6d0cc25d905_cerberus_enhanced.tif_full.jpg\n",
      "https://astrogeology.usgs.gov/cache/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg\n",
      "https://astrogeology.usgs.gov/cache/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg\n",
      "https://astrogeology.usgs.gov/cache/images/b3c7c6c9138f57b4756be9b9c43e3a48_valles_marineris_enhanced.tif_full.jpg\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Create a list to hold the image urls\n",
    "title_urls = []\n",
    "for url in link_urls:\n",
    "    # Visit the url using browser.visit method\n",
    "    browser.visit(url)\n",
    "    # Instantiate button click\n",
    "    button = browser.find_by_id(\"wide-image-toggle\")\n",
    "    button.click()\n",
    "    # Set delay for 1s to make sure the webpage loads correctly\n",
    "    time.sleep(1)\n",
    "    # Visit the url with wide-image\n",
    "    html = browser.html\n",
    "    # Create BeautifulSoup object; parse with 'html.parser'\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Find the url for the wide-image\n",
    "    img_url = soup.find('img',class_=\"wide-image\")['src']\n",
    "    # Combine with the base_url to create the correct url\n",
    "    image_url = base_url + img_url\n",
    "    print(image_url)\n",
    "    # Append the list\n",
    "    title_urls.append(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astrogeology.usgs.gov/cache/images/f5e372a36edfa389625da6d0cc25d905_cerberus_enhanced.tif_full.jpg'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'https://astrogeology.usgs.gov/cache/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'https://astrogeology.usgs.gov/cache/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'https://astrogeology.usgs.gov/cache/images/b3c7c6c9138f57b4756be9b9c43e3a48_valles_marineris_enhanced.tif_full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "# Lets create a list of dictionaries\n",
    "hemisphere_urls = [] \n",
    "item_dict = {} \n",
    "for i in range(len(titles)):\n",
    "    item_dict[\"title\"] = titles[i]\n",
    "    item_dict[\"img_url\"] = title_urls[i]\n",
    "    hemisphere_urls.append(item_dict.copy())\n",
    "# Display the list of dictionaries\n",
    "print(hemisphere_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Screenshots/Cerberus.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "from IPython.display import Image\n",
    "# Use the requests library to download and save the image from the first url\n",
    "response = requests.get(title_urls[0], stream=True)\n",
    "with open('Screenshots/Cerberus.png', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "# Display the image with IPython.display\n",
    "Image(url='Screenshots/Cerberus.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Screenshots/Schiaparelli.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the requests library to download and save the image from the first url\n",
    "response = requests.get(title_urls[1], stream=True)\n",
    "with open('Screenshots/Schiaparelli.png', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "# Display the image with IPython.display\n",
    "Image(url='Screenshots/Schiaparelli.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Screenshots/Syrtis_major.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the requests library to download and save the image from the first url\n",
    "response = requests.get(title_urls[2], stream=True)\n",
    "with open('Screenshots/Syrtis_major.png', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "# Display the image with IPython.display\n",
    "Image(url='Screenshots/Syrtis_major.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Screenshots/Valles_marineris.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the requests library to download and save the image from the first url\n",
    "response = requests.get(title_urls[3], stream=True)\n",
    "with open('Screenshots/Valles_marineris.png', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "# Display the image with IPython.display\n",
    "Image(url='Screenshots/Valles_marineris.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing browser using browser.quit:\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
